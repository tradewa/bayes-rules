---
title: "Chapter 2"
format: html
---

```{r}
# Load package
library(bayesrules)
library(tidyverse)
library(janitor)
```


```{r}
rm(list = ls())

# Import article data
data(fake_news)
```

```{r}
fake_news %>% 
  tabyl(type) %>% 
  adorn_totals("row")
```

```{r}
fake_news %>% 
  tabyl(title_has_excl, type) %>% 
  adorn_totals("row")
```

### 2.1.5 Posterior simulation
```{r}
# Define possible articles
article <- data.frame(type = c("real", "fake"))

# Define the prior model
prior <- c(0.6, 0.4)
```

```{r}
# Set the seed. Simulate 3 articles.
set.seed(84735)
sample_n(article, size = 3, weight = prior, replace = TRUE)
```
```{r}
# Simulate 10000 articles.
set.seed(84735)
article_sim <-
  sample_n(article, size = 10000,
           weight = prior, replace = TRUE)
```

```{r}
ggplot(article_sim, aes(x = type)) +
  geom_bar()
```

```{r}
article_sim %>% 
  tabyl(type) %>% 
  adorn_totals("row")
```

Simulate exclamation point usage among 10,000 articles. The data_model variable specifies that there's a 26.67% chance that any fake article and a 2.22% chance that any real article uses exclamation points:
```{r}
article_sim <-
  article_sim %>% 
  mutate(data_model = case_when(type == "fake" ~ 0.2667,
                                type == "real" ~ 0.0222))

glimpse(article_sim)
```

```{r}
# Define whether there are exclamation points
data <- c("no", "yes")

# Simulate exclamation point usage
set.seed(3)
article_sim <-
  article_sim %>% 
  group_by(1:n()) %>% 
  mutate(usage = sample(data, size = 1,
                        prob = c(1 - data_model, data_model)))
```

```{r}
article_sim %>% 
  tabyl(usage, type) %>% 
  adorn_totals(c("col", "row"))
```

```{r}
ggplot(article_sim, aes(x = type, fill = usage)) +
  geom_bar(position = "fill")

ggplot(article_sim, aes(x = type)) +
  geom_bar()
```

```{r}
article_sim %>% 
  filter(usage == "yes") %>% 
  tabyl(type) %>% 
  adorn_totals("row")
```

```{r}
ggplot(article_sim, aes(x = type)) +
  geom_bar() +
  facet_wrap(~ usage)
```

## 2.2 Example: Pop vs soda vs coke
```{r}
# Load the data
data("pop_vs_soda")

# Summarize pop use by region
pop_vs_soda %>% 
  tabyl(pop, region) %>% 
  adorn_percentages("col")
```

Posterior probability that the person live in south after knowing that he said pop
```{r}
pop_vs_soda %>% 
  tabyl(region, pop) %>% 
  adorn_percentages("row") %>% 
  as_tibble()
```

## 2.3 Building a Bayesian model for random variables
### 2.3.1 Prior probability model
### 2.3.2 The Binomial data model
### 2.3.3 The Binomial likelihood function
### 2.3.4 Normalizing constant
### 2.3.5 Posterior probability model
### 2.3.6 Posterior shortcut
### 2.3.7 Posterior simulation
```{r}
# Define possible win probabilities
chess <- data.frame(pi = c(0.2, 0.5, 0.8))

# Define the prior model
prior <- c(0.1, 0.25, 0.65)
```

```{r}
# Simulate 10000 values of pi from the prior
set.seed(84735)
chess_sim <- sample_n(chess, size = 10000, weight = prior, replace = TRUE)
```

```{r}
# Simulate 10000 match outcomes
chess_sim <- chess_sim %>% 
  mutate(y = rbinom(10000, size = 6, prob = pi))

# Check it out
chess_sim %>% 
  head(3)
```

```{r}
# Summarize the prior
chess_sim %>% 
  tabyl(pi) %>% 
  adorn_totals("row")
```

```{r}
# Plot y by pi
ggplot(chess_sim, aes(x = y)) +
  stat_count(aes(y = after_stat(prop))) +
  facet_wrap(~ pi)
```

```{r}
# Focus on simulations with y = 1
win_one <- chess_sim %>% 
  filter(y == 1)

# Summarize the posterior approximation
win_one %>% 
  tabyl(pi) %>% 
  adorn_totals("row")

# Plot the posterior approximation
ggplot(win_one, aes(x = pi)) +
  geom_bar()
```

## 2.5 Exercies
